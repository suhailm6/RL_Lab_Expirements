{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10183210-903c-4f30-a21b-b297c757de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Episode........\n",
      "Step 0: State = 0, Action = 1, Nextstate, reward = 0\n",
      "Step 1: State = 1, Action = 1, Nextstate, reward = 0\n",
      "Step 2: State = 2, Action = 1, Nextstate, reward = 0\n",
      "Step 3: State = 3, Action = -1, Nextstate, reward = 0\n",
      "Step 4: State = 2, Action = 1, Nextstate, reward = 0\n",
      "Step 5: State = 3, Action = 1, Nextstate, reward = 0\n",
      "Step 6: State = 4, Action = 1, Nextstate, reward = 10\n",
      "Episode completed in 7 steps.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class Enviroment:\n",
    "    def __init__(self):\n",
    "        self.state = 0\n",
    "    def reset(self):\n",
    "        self.state = 0\n",
    "        return self.state\n",
    "    def step(self ,action ):\n",
    "        self.state += action\n",
    "        if self.state == 5:\n",
    "            reward = 10\n",
    "            done = True\n",
    "        else:\n",
    "            reward = 0\n",
    "            done = False\n",
    "        return self.state , reward , done\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.actions = [-1 , +1]\n",
    "    def select_action(self):\n",
    "        return random.choice(self.actions)\n",
    "env = Enviroment()\n",
    "agent = Agent()\n",
    "state = env.reset()\n",
    "done = False\n",
    "step_count =0\n",
    "print(\"Starting Episode........\")\n",
    "while not done :\n",
    "    action = agent.select_action()\n",
    "    next_state, reward, done = env.step(action)\n",
    "    print(f\"Step {step_count}: State = {state}, Action = {action}, Nextstate, reward = {reward}\")\n",
    "    state = next_state\n",
    "    step_count += 1\n",
    "\n",
    "print(f\"Episode completed in {step_count} steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a29d227-03a4-485e-89fe-f30474fb4911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Treasure Hunt Episode...\n",
      "\n",
      "Step 0: State = 0, Action = 1, NextState = 1, Reward = 0\n",
      "Step 1: State = 1, Action = -1, NextState = 0, Reward = 0\n",
      "Step 2: State = 0, Action = 1, NextState = 1, Reward = 0\n",
      "Step 3: State = 1, Action = -1, NextState = 0, Reward = 0\n",
      "Step 4: State = 0, Action = 1, NextState = 1, Reward = 0\n",
      "Step 5: State = 1, Action = -1, NextState = 0, Reward = 0\n",
      "Step 6: State = 0, Action = 1, NextState = 1, Reward = 0\n",
      "Step 7: State = 1, Action = 1, NextState = 2, Reward = 0\n",
      "Step 8: State = 2, Action = -1, NextState = 1, Reward = 0\n",
      "Step 9: State = 1, Action = 1, NextState = 2, Reward = 0\n",
      "Step 10: State = 2, Action = 1, NextState = 3, Reward = 0\n",
      "Step 11: State = 3, Action = 1, NextState = 4, Reward = 0\n",
      "Step 12: State = 4, Action = 1, NextState = 5, Reward = -5\n",
      "Step 13: State = 5, Action = -1, NextState = 4, Reward = 0\n",
      "Step 14: State = 4, Action = 1, NextState = 5, Reward = -5\n",
      "Step 15: State = 5, Action = -1, NextState = 4, Reward = 0\n",
      "Step 16: State = 4, Action = -1, NextState = 3, Reward = 0\n",
      "Step 17: State = 3, Action = -1, NextState = 2, Reward = 0\n",
      "Step 18: State = 2, Action = -1, NextState = 1, Reward = 0\n",
      "Step 19: State = 1, Action = -1, NextState = 0, Reward = 0\n",
      "Step 20: State = 0, Action = 1, NextState = 1, Reward = 0\n",
      "Step 21: State = 1, Action = -1, NextState = 0, Reward = 0\n",
      "Step 22: State = 0, Action = -1, NextState = -1, Reward = 0\n",
      "Step 23: State = -1, Action = 1, NextState = 0, Reward = 0\n",
      "Step 24: State = 0, Action = -1, NextState = -1, Reward = 0\n",
      "Step 25: State = -1, Action = 1, NextState = 0, Reward = 0\n",
      "Step 26: State = 0, Action = -1, NextState = -1, Reward = 0\n",
      "Step 27: State = -1, Action = -1, NextState = -2, Reward = 0\n",
      "Step 28: State = -2, Action = -1, NextState = -3, Reward = 0\n",
      "Step 29: State = -3, Action = -1, NextState = -4, Reward = 0\n",
      "Step 30: State = -4, Action = -1, NextState = -5, Reward = 0\n",
      "Step 31: State = -5, Action = 1, NextState = -4, Reward = 0\n",
      "Step 32: State = -4, Action = 1, NextState = -3, Reward = 0\n",
      "Step 33: State = -3, Action = -1, NextState = -4, Reward = 0\n",
      "Step 34: State = -4, Action = -1, NextState = -5, Reward = 0\n",
      "Step 35: State = -5, Action = -1, NextState = -6, Reward = 0\n",
      "Step 36: State = -6, Action = -1, NextState = -7, Reward = 0\n",
      "Step 37: State = -7, Action = 1, NextState = -6, Reward = 0\n",
      "Step 38: State = -6, Action = -1, NextState = -7, Reward = 0\n",
      "Step 39: State = -7, Action = -1, NextState = -8, Reward = 0\n",
      "Step 40: State = -8, Action = -1, NextState = -9, Reward = 0\n",
      "Step 41: State = -9, Action = 1, NextState = -8, Reward = 0\n",
      "Step 42: State = -8, Action = -1, NextState = -9, Reward = 0\n",
      "Step 43: State = -9, Action = -1, NextState = -10, Reward = 0\n",
      "Step 44: State = -10, Action = -1, NextState = -11, Reward = 0\n",
      "Step 45: State = -11, Action = 1, NextState = -10, Reward = 0\n",
      "Step 46: State = -10, Action = 1, NextState = -9, Reward = 0\n",
      "Step 47: State = -9, Action = -1, NextState = -10, Reward = 0\n",
      "Step 48: State = -10, Action = 1, NextState = -9, Reward = 0\n",
      "Step 49: State = -9, Action = -1, NextState = -10, Reward = 0\n",
      "Step 50: State = -10, Action = -1, NextState = -11, Reward = 0\n",
      "Step 51: State = -11, Action = -1, NextState = -12, Reward = 0\n",
      "Step 52: State = -12, Action = 1, NextState = -11, Reward = 0\n",
      "Step 53: State = -11, Action = -1, NextState = -12, Reward = 0\n",
      "Step 54: State = -12, Action = -1, NextState = -13, Reward = 0\n",
      "Step 55: State = -13, Action = 1, NextState = -12, Reward = 0\n",
      "Step 56: State = -12, Action = 1, NextState = -11, Reward = 0\n",
      "Step 57: State = -11, Action = -1, NextState = -12, Reward = 0\n",
      "Step 58: State = -12, Action = 1, NextState = -11, Reward = 0\n",
      "Step 59: State = -11, Action = 1, NextState = -10, Reward = 0\n",
      "Step 60: State = -10, Action = 1, NextState = -9, Reward = 0\n",
      "Step 61: State = -9, Action = -1, NextState = -10, Reward = 0\n",
      "Step 62: State = -10, Action = 1, NextState = -9, Reward = 0\n",
      "Step 63: State = -9, Action = 1, NextState = -8, Reward = 0\n",
      "Step 64: State = -8, Action = 1, NextState = -7, Reward = 0\n",
      "Step 65: State = -7, Action = -1, NextState = -8, Reward = 0\n",
      "Step 66: State = -8, Action = 1, NextState = -7, Reward = 0\n",
      "Step 67: State = -7, Action = -1, NextState = -8, Reward = 0\n",
      "Step 68: State = -8, Action = 1, NextState = -7, Reward = 0\n",
      "Step 69: State = -7, Action = -1, NextState = -8, Reward = 0\n",
      "Step 70: State = -8, Action = 1, NextState = -7, Reward = 0\n",
      "Step 71: State = -7, Action = -1, NextState = -8, Reward = 0\n",
      "Step 72: State = -8, Action = 1, NextState = -7, Reward = 0\n",
      "Step 73: State = -7, Action = 1, NextState = -6, Reward = 0\n",
      "Step 74: State = -6, Action = -1, NextState = -7, Reward = 0\n",
      "Step 75: State = -7, Action = -1, NextState = -8, Reward = 0\n",
      "Step 76: State = -8, Action = 1, NextState = -7, Reward = 0\n",
      "Step 77: State = -7, Action = -1, NextState = -8, Reward = 0\n",
      "Step 78: State = -8, Action = -1, NextState = -9, Reward = 0\n",
      "Step 79: State = -9, Action = 1, NextState = -8, Reward = 0\n",
      "Step 80: State = -8, Action = 1, NextState = -7, Reward = 0\n",
      "Step 81: State = -7, Action = 1, NextState = -6, Reward = 0\n",
      "Step 82: State = -6, Action = -1, NextState = -7, Reward = 0\n",
      "Step 83: State = -7, Action = -1, NextState = -8, Reward = 0\n",
      "Step 84: State = -8, Action = 1, NextState = -7, Reward = 0\n",
      "Step 85: State = -7, Action = -1, NextState = -8, Reward = 0\n",
      "Step 86: State = -8, Action = 1, NextState = -7, Reward = 0\n",
      "Step 87: State = -7, Action = 1, NextState = -6, Reward = 0\n",
      "Step 88: State = -6, Action = -1, NextState = -7, Reward = 0\n",
      "Step 89: State = -7, Action = -1, NextState = -8, Reward = 0\n",
      "Step 90: State = -8, Action = 1, NextState = -7, Reward = 0\n",
      "Step 91: State = -7, Action = 1, NextState = -6, Reward = 0\n",
      "Step 92: State = -6, Action = -1, NextState = -7, Reward = 0\n",
      "Step 93: State = -7, Action = -1, NextState = -8, Reward = 0\n",
      "Step 94: State = -8, Action = 1, NextState = -7, Reward = 0\n",
      "Step 95: State = -7, Action = 1, NextState = -6, Reward = 0\n",
      "Step 96: State = -6, Action = 1, NextState = -5, Reward = 0\n",
      "Step 97: State = -5, Action = 1, NextState = -4, Reward = 0\n",
      "Step 98: State = -4, Action = 1, NextState = -3, Reward = 0\n",
      "Step 99: State = -3, Action = 1, NextState = -2, Reward = 0\n",
      "Step 100: State = -2, Action = -1, NextState = -3, Reward = 0\n",
      "Step 101: State = -3, Action = -1, NextState = -4, Reward = 0\n",
      "Step 102: State = -4, Action = 1, NextState = -3, Reward = 0\n",
      "Step 103: State = -3, Action = -1, NextState = -4, Reward = 0\n",
      "Step 104: State = -4, Action = -1, NextState = -5, Reward = 0\n",
      "Step 105: State = -5, Action = 1, NextState = -4, Reward = 0\n",
      "Step 106: State = -4, Action = 1, NextState = -3, Reward = 0\n",
      "Step 107: State = -3, Action = 1, NextState = -2, Reward = 0\n",
      "Step 108: State = -2, Action = -1, NextState = -3, Reward = 0\n",
      "Step 109: State = -3, Action = -1, NextState = -4, Reward = 0\n",
      "Step 110: State = -4, Action = 1, NextState = -3, Reward = 0\n",
      "Step 111: State = -3, Action = 1, NextState = -2, Reward = 0\n",
      "Step 112: State = -2, Action = 1, NextState = -1, Reward = 0\n",
      "Step 113: State = -1, Action = 1, NextState = 0, Reward = 0\n",
      "Step 114: State = 0, Action = 1, NextState = 1, Reward = 0\n",
      "Step 115: State = 1, Action = -1, NextState = 0, Reward = 0\n",
      "Step 116: State = 0, Action = 1, NextState = 1, Reward = 0\n",
      "Step 117: State = 1, Action = 1, NextState = 2, Reward = 0\n",
      "Step 118: State = 2, Action = 1, NextState = 3, Reward = 0\n",
      "Step 119: State = 3, Action = 1, NextState = 4, Reward = 0\n",
      "Step 120: State = 4, Action = 1, NextState = 5, Reward = -5\n",
      "Step 121: State = 5, Action = -1, NextState = 4, Reward = 0\n",
      "Step 122: State = 4, Action = 1, NextState = 5, Reward = -5\n",
      "Step 123: State = 5, Action = -1, NextState = 4, Reward = 0\n",
      "Step 124: State = 4, Action = 1, NextState = 5, Reward = -5\n",
      "Step 125: State = 5, Action = -1, NextState = 4, Reward = 0\n",
      "Step 126: State = 4, Action = -1, NextState = 3, Reward = 0\n",
      "Step 127: State = 3, Action = 1, NextState = 4, Reward = 0\n",
      "Step 128: State = 4, Action = 1, NextState = 5, Reward = -5\n",
      "Step 129: State = 5, Action = -1, NextState = 4, Reward = 0\n",
      "Step 130: State = 4, Action = -1, NextState = 3, Reward = 0\n",
      "Step 131: State = 3, Action = -1, NextState = 2, Reward = 0\n",
      "Step 132: State = 2, Action = -1, NextState = 1, Reward = 0\n",
      "Step 133: State = 1, Action = -1, NextState = 0, Reward = 0\n",
      "Step 134: State = 0, Action = 1, NextState = 1, Reward = 0\n",
      "Step 135: State = 1, Action = 1, NextState = 2, Reward = 0\n",
      "Step 136: State = 2, Action = 1, NextState = 3, Reward = 0\n",
      "Step 137: State = 3, Action = 1, NextState = 4, Reward = 0\n",
      "Step 138: State = 4, Action = 1, NextState = 5, Reward = -5\n",
      "Step 139: State = 5, Action = -1, NextState = 4, Reward = 0\n",
      "Step 140: State = 4, Action = 1, NextState = 5, Reward = -5\n",
      "Step 141: State = 5, Action = -1, NextState = 4, Reward = 0\n",
      "Step 142: State = 4, Action = 1, NextState = 5, Reward = -5\n",
      "Step 143: State = 5, Action = 1, NextState = 6, Reward = 0\n",
      "Step 144: State = 6, Action = 1, NextState = 7, Reward = 0\n",
      "Step 145: State = 7, Action = -1, NextState = 6, Reward = 0\n",
      "Step 146: State = 6, Action = -1, NextState = 5, Reward = -5\n",
      "Step 147: State = 5, Action = 1, NextState = 6, Reward = 0\n",
      "Step 148: State = 6, Action = 1, NextState = 7, Reward = 0\n",
      "Step 149: State = 7, Action = 1, NextState = 8, Reward = 0\n",
      "Step 150: State = 8, Action = -1, NextState = 7, Reward = 0\n",
      "Step 151: State = 7, Action = 1, NextState = 8, Reward = 0\n",
      "Step 152: State = 8, Action = 1, NextState = 9, Reward = 0\n",
      "Step 153: State = 9, Action = 1, NextState = 10, Reward = 20\n",
      "\n",
      " Episode completed in 154 steps.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.state = 0\n",
    "    def reset(self):\n",
    "        self.state = 0\n",
    "        return self.state\n",
    "    def step(self, action):\n",
    "        self.state += action\n",
    "        if self.state == 10:\n",
    "            reward = 20\n",
    "            done = True\n",
    "        elif self.state == 5:\n",
    "            reward = -5\n",
    "            done = False\n",
    "        else:\n",
    "            reward = 0\n",
    "            done = False\n",
    "        return self.state, reward, done\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.actions = [-1, 1]\n",
    "    def select_action(self):\n",
    "        return random.choice(self.actions)\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "state = env.reset()\n",
    "done = False\n",
    "step_count = 0\n",
    "print(\"Starting Treasure Hunt Episode...\\n\")\n",
    "while not done:\n",
    "    action = agent.select_action()\n",
    "    next_state, reward, done = env.step(action)\n",
    "    print(f\"Step {step_count}: State = {state}, Action = {action}, NextState = {next_state}, Reward = {reward}\")\n",
    "    state = next_state\n",
    "    step_count += 1\n",
    "print(f\"\\n Episode completed in {step_count} steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27688bb5-8f13-4953-a687-096baf7e85aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
