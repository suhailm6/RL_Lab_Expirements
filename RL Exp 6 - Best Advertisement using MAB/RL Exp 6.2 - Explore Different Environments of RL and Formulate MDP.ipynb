{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ac5ed6-2b1c-4b3d-800a-fa143d4b00e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Downloading gymnasium-1.2.1-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gymnasium) (2.3.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gymnasium) (4.14.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Downloading gymnasium-1.2.1-py3-none-any.whl (951 kB)\n",
      "   ---------------------------------------- 0.0/951.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/951.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 951.1/951.1 kB 4.5 MB/s  0:00:00\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, gymnasium\n",
      "\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   ---------------------------------------- 2/2 [gymnasium]\n",
      "\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-1.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9b41c1-1ced-42a3-92d4-135efbc84978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of environments: 63\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of Environments\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "envs = gym.envs.registry\n",
    "total_envs = len(envs)\n",
    "print(f\"Total number of environments: {total_envs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b29093e-6650-4939-9f52-ce4d0b003ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acrobot-v1\n",
      "Ant-v2\n",
      "Ant-v3\n",
      "Ant-v4\n",
      "Ant-v5\n",
      "BipedalWalker-v3\n",
      "BipedalWalkerHardcore-v3\n",
      "Blackjack-v1\n",
      "CarRacing-v3\n",
      "CartPole-v0\n",
      "CartPole-v1\n",
      "CliffWalking-v1\n",
      "CliffWalkingSlippery-v1\n",
      "FrozenLake-v1\n",
      "FrozenLake8x8-v1\n",
      "GymV21Environment-v0\n",
      "GymV26Environment-v0\n",
      "HalfCheetah-v2\n",
      "HalfCheetah-v3\n",
      "HalfCheetah-v4\n",
      "HalfCheetah-v5\n",
      "Hopper-v2\n",
      "Hopper-v3\n",
      "Hopper-v4\n",
      "Hopper-v5\n",
      "Humanoid-v2\n",
      "Humanoid-v3\n",
      "Humanoid-v4\n",
      "Humanoid-v5\n",
      "HumanoidStandup-v2\n",
      "HumanoidStandup-v4\n",
      "HumanoidStandup-v5\n",
      "InvertedDoublePendulum-v2\n",
      "InvertedDoublePendulum-v4\n",
      "InvertedDoublePendulum-v5\n",
      "InvertedPendulum-v2\n",
      "InvertedPendulum-v4\n",
      "InvertedPendulum-v5\n",
      "LunarLander-v3\n",
      "LunarLanderContinuous-v3\n",
      "MountainCar-v0\n",
      "MountainCarContinuous-v0\n",
      "Pendulum-v1\n",
      "Pusher-v2\n",
      "Pusher-v4\n",
      "Pusher-v5\n",
      "Reacher-v2\n",
      "Reacher-v4\n",
      "Reacher-v5\n",
      "Swimmer-v2\n",
      "Swimmer-v3\n",
      "Swimmer-v4\n",
      "Swimmer-v5\n",
      "Taxi-v3\n",
      "Walker2d-v2\n",
      "Walker2d-v3\n",
      "Walker2d-v4\n",
      "Walker2d-v5\n",
      "phys2d/CartPole-v0\n",
      "phys2d/CartPole-v1\n",
      "phys2d/Pendulum-v0\n",
      "tabular/Blackjack-v0\n",
      "tabular/CliffWalking-v0\n"
     ]
    }
   ],
   "source": [
    "# Print all environments\n",
    "envs = gym.envs.registry\n",
    "\n",
    "env_names = sorted([env_spec for env_spec in envs])\n",
    "for name in env_names:\n",
    "  print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a29128-419b-4466-a810-0bc9c09e98e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(2)\n",
      "Observation Space: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
      "Initial State:\n",
      "Cart Position: -0.03708511218428612\n",
      "Cart Velocity: 0.029815340414643288\n",
      "Pole Angle: 0.04063794016838074\n",
      "Pole Velocity: 0.04627298191189766\n",
      "Action 0: Move Left\n",
      "Action 1: Move Right\n",
      "\n",
      "Simulating a few steps:\n",
      "\n",
      "Step 1:\n",
      "Action taken: Move Left\n",
      "Next State:\n",
      "Cart Position: -0.03648880496621132\n",
      "Cart Velocity: -0.16586506366729736\n",
      "Pole Angle: 0.04156339913606644\n",
      "Pole Velocity: 0.35149550437927246\n",
      "Reward: 1.0\n",
      "Done: False\n",
      "\n",
      "Step 2:\n",
      "Action taken: Move Left\n",
      "Next State:\n",
      "Cart Position: -0.03980610519647598\n",
      "Cart Velocity: -0.3615526854991913\n",
      "Pole Angle: 0.04859331250190735\n",
      "Pole Velocity: 0.656989574432373\n",
      "Reward: 1.0\n",
      "Done: False\n",
      "\n",
      "Step 3:\n",
      "Action taken: Move Right\n",
      "Next State:\n",
      "Cart Position: -0.04703715816140175\n",
      "Cart Velocity: -0.16713963449001312\n",
      "Pole Angle: 0.061733100563287735\n",
      "Pole Velocity: 0.37999504804611206\n",
      "Reward: 1.0\n",
      "Done: False\n",
      "\n",
      "Step 4:\n",
      "Action taken: Move Right\n",
      "Next State:\n",
      "Cart Position: -0.05037995055317879\n",
      "Cart Velocity: 0.0270538292825222\n",
      "Pole Angle: 0.06933300197124481\n",
      "Pole Velocity: 0.10739772766828537\n",
      "Reward: 1.0\n",
      "Done: False\n",
      "\n",
      "Step 5:\n",
      "Action taken: Move Right\n",
      "Next State:\n",
      "Cart Position: -0.049838874489068985\n",
      "Cart Velocity: 0.22111725807189941\n",
      "Pole Angle: 0.07148095965385437\n",
      "Pole Velocity: -0.16263046860694885\n",
      "Reward: 1.0\n",
      "Done: False\n"
     ]
    }
   ],
   "source": [
    "# CartPole-v1\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "print(f\"Action Space: {env.action_space}\")\n",
    "print(f\"Observation Space: {env.observation_space}\")\n",
    "\n",
    "def describe_state(state):\n",
    "    \"\"\"\n",
    "    This function prints out the individual components of the state\n",
    "    State is a tuple (x, x_dot, theta, theta_dot)\n",
    "    \"\"\"\n",
    "    cart_position, cart_velocity, pole_angle, pole_velocity = state\n",
    "    print(f\"Cart Position: {cart_position}\")\n",
    "    print(f\"Cart Velocity: {cart_velocity}\")\n",
    "    print(f\"Pole Angle: {pole_angle}\")\n",
    "    print(f\"Pole Velocity: {pole_velocity}\")\n",
    "\n",
    "print(\"Initial State:\")\n",
    "describe_state(state)\n",
    "\n",
    "actions = {0: \"Move Left\", 1: \"Move Right\"}\n",
    "for action in actions:\n",
    "    print(f\"Action {action}: {actions[action]}\")\n",
    "\n",
    "num_steps = 5\n",
    "print(\"\\nSimulating a few steps:\")\n",
    "for step in range(num_steps):\n",
    "    action = env.action_space.sample()  \n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    print(f\"\\nStep {step + 1}:\")\n",
    "    print(f\"Action taken: {actions[action]}\")\n",
    "    print(\"Next State:\")\n",
    "    describe_state(next_state)\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc311ac2-baf7-4e92-8ffa-f03b16e2182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(2)\n",
      "Observation Space: Tuple(Discrete(32), Discrete(11), Discrete(2))\n",
      "Initial State:\n",
      "Player's Sum: 6\n",
      "Dealer's Card: 10\n",
      "Usable Ace: No\n",
      "Action 0: Stick\n",
      "Action 1: Hit\n",
      "\n",
      "Simulating a few steps:\n",
      "\n",
      "Step 1:\n",
      "Action taken: Hit\n",
      "Next State:\n",
      "Player's Sum: 16\n",
      "Dealer's Card: 10\n",
      "Usable Ace: No\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "\n",
      "Step 2:\n",
      "Action taken: Hit\n",
      "Next State:\n",
      "Player's Sum: 26\n",
      "Dealer's Card: 10\n",
      "Usable Ace: No\n",
      "Reward: -1.0\n",
      "Done: True\n"
     ]
    }
   ],
   "source": [
    "# Blackjack-v1\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('Blackjack-v1')\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "print(f\"Action Space: {env.action_space}\")\n",
    "print(f\"Observation Space: {env.observation_space}\")\n",
    "\n",
    "def describe_state(state):\n",
    "    \"\"\"\n",
    "    This function prints out the individual components of the state\n",
    "    State is a tuple: (player_sum, dealer_card, usable_ace)\n",
    "    \"\"\"\n",
    "    player_sum, dealer_card, usable_ace = state\n",
    "    print(f\"Player's Sum: {player_sum}\")\n",
    "    print(f\"Dealer's Card: {dealer_card}\")\n",
    "    print(f\"Usable Ace: {'Yes' if usable_ace else 'No'}\")\n",
    "\n",
    "print(\"Initial State:\")\n",
    "describe_state(state)\n",
    "\n",
    "actions = {0: \"Stick\", 1: \"Hit\"}\n",
    "for action in actions:\n",
    "    print(f\"Action {action}: {actions[action]}\")\n",
    "\n",
    "num_steps = 5\n",
    "print(\"\\nSimulating a few steps:\")\n",
    "for step in range(num_steps):\n",
    "    action = env.action_space.sample()  \n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    print(f\"\\nStep {step + 1}:\")\n",
    "    print(f\"Action taken: {actions[action]}\")\n",
    "    print(\"Next State:\")\n",
    "    describe_state(next_state)\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}\")\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e22a2b-8abf-4e2c-906c-c77630f238d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(3)\n",
      "Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "Initial State:\n",
      "Position: -0.44060999155044556\n",
      "Velocity: 0.0\n",
      "Action 0: Push Left\n",
      "Action 1: No Push\n",
      "Action 2: Push Right\n",
      "\n",
      "Simulating a few steps:\n",
      "\n",
      "Step 1:\n",
      "Action taken: No Push\n",
      "Next State:\n",
      "Position: -0.4412260055541992\n",
      "Velocity: -0.0006160058546811342\n",
      "Reward: -1.0\n",
      "Done: False\n",
      "\n",
      "Step 2:\n",
      "Action taken: No Push\n",
      "Next State:\n",
      "Position: -0.442453533411026\n",
      "Velocity: -0.0012275329791009426\n",
      "Reward: -1.0\n",
      "Done: False\n",
      "\n",
      "Step 3:\n",
      "Action taken: Push Right\n",
      "Next State:\n",
      "Position: -0.44328364729881287\n",
      "Velocity: -0.0008301292546093464\n",
      "Reward: -1.0\n",
      "Done: False\n",
      "\n",
      "Step 4:\n",
      "Action taken: Push Left\n",
      "Next State:\n",
      "Position: -0.44571033120155334\n",
      "Velocity: -0.0024266813416033983\n",
      "Reward: -1.0\n",
      "Done: False\n",
      "\n",
      "Step 5:\n",
      "Action taken: Push Right\n",
      "Next State:\n",
      "Position: -0.4477158784866333\n",
      "Velocity: -0.0020055430941283703\n",
      "Reward: -1.0\n",
      "Done: False\n"
     ]
    }
   ],
   "source": [
    "# MountainCar-v0\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "print(f\"Action Space: {env.action_space}\")\n",
    "print(f\"Observation Space: {env.observation_space}\")\n",
    "\n",
    "\n",
    "def describe_state(state):\n",
    "    \"\"\"\n",
    "    This function prints out the individual components of the state\n",
    "    State is a tuple: (position, velocity)\n",
    "    \"\"\"\n",
    "    position, velocity = state\n",
    "    print(f\"Position: {position}\")\n",
    "    print(f\"Velocity: {velocity}\")\n",
    "\n",
    "print(\"Initial State:\")\n",
    "describe_state(state)\n",
    "\n",
    "actions = {0: \"Push Left\", 1: \"No Push\", 2: \"Push Right\"}\n",
    "for action in actions:\n",
    "    print(f\"Action {action}: {actions[action]}\")\n",
    "\n",
    "num_steps = 5\n",
    "print(\"\\nSimulating a few steps:\")\n",
    "for step in range(num_steps):\n",
    "    action = env.action_space.sample() \n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    print(f\"\\nStep {step + 1}:\")\n",
    "    print(f\"Action taken: {actions[action]}\")\n",
    "    print(\"Next State:\")\n",
    "    describe_state(next_state)\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}\")\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b0459a3-a15a-41c4-b5f7-1ef7f809f6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(4)\n",
      "Observation Space: Discrete(16)\n",
      "Initial State: 0\n",
      "Action 0: Left\n",
      "Action 1: Down\n",
      "Action 2: Right\n",
      "Action 3: Up\n",
      "\n",
      "Simulating a few steps:\n",
      "\n",
      "Step 1:\n",
      "Action taken: Left\n",
      "Next State: 0\n",
      "Reward: 0\n",
      "Done: False\n",
      "\n",
      "Step 2:\n",
      "Action taken: Down\n",
      "Next State: 4\n",
      "Reward: 0\n",
      "Done: False\n",
      "\n",
      "Step 3:\n",
      "Action taken: Left\n",
      "Next State: 8\n",
      "Reward: 0\n",
      "Done: False\n",
      "\n",
      "Step 4:\n",
      "Action taken: Left\n",
      "Next State: 8\n",
      "Reward: 0\n",
      "Done: False\n",
      "\n",
      "Step 5:\n",
      "Action taken: Left\n",
      "Next State: 4\n",
      "Reward: 0\n",
      "Done: False\n"
     ]
    }
   ],
   "source": [
    "# FrozenLake-v1\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('FrozenLake-v1')\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "print(f\"Action Space: {env.action_space}\")\n",
    "print(f\"Observation Space: {env.observation_space}\")\n",
    "\n",
    "print(f\"Initial State: {state}\")\n",
    "\n",
    "actions = {0: \"Left\", 1: \"Down\", 2: \"Right\", 3: \"Up\"}\n",
    "for action in actions:\n",
    "    print(f\"Action {action}: {actions[action]}\")\n",
    "\n",
    "num_steps = 5\n",
    "print(\"\\nSimulating a few steps:\")\n",
    "for step in range(num_steps):\n",
    "    action = env.action_space.sample()  \n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    print(f\"\\nStep {step + 1}:\")\n",
    "    print(f\"Action taken: {actions[action]}\")\n",
    "    print(f\"Next State: {next_state}\")\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}\")\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c62d62a-774b-47c9-9490-a2f0c6544777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(6)\n",
      "Observation Space: Discrete(500)\n",
      "Initial State: 101\n",
      "Action 0: Down\n",
      "Action 1: Up\n",
      "Action 2: Right\n",
      "Action 3: Left\n",
      "Action 4: Pickup\n",
      "Action 5: Dropoff\n",
      "\n",
      "Simulating a few steps:\n",
      "\n",
      "Step 1:\n",
      "Action taken: Down\n",
      "Next State: 201\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "Step 2:\n",
      "Action taken: Right\n",
      "Next State: 221\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "Step 3:\n",
      "Action taken: Up\n",
      "Next State: 121\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "Step 4:\n",
      "Action taken: Down\n",
      "Next State: 221\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "Step 5:\n",
      "Action taken: Pickup\n",
      "Next State: 221\n",
      "Reward: -10\n",
      "Done: False\n"
     ]
    }
   ],
   "source": [
    "# Taxi-v3\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "print(f\"Action Space: {env.action_space}\")\n",
    "print(f\"Observation Space: {env.observation_space}\")\n",
    "\n",
    "print(f\"Initial State: {state}\")\n",
    "\n",
    "actions = {0: \"Down\", 1: \"Up\", 2: \"Right\", 3: \"Left\", 4: \"Pickup\", 5: \"Dropoff\"}\n",
    "for action in actions:\n",
    "    print(f\"Action {action}: {actions[action]}\")\n",
    "\n",
    "num_steps = 5\n",
    "print(\"\\nSimulating a few steps:\")\n",
    "for step in range(num_steps):\n",
    "    action = env.action_space.sample()  # Random action\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    print(f\"\\nStep {step + 1}:\")\n",
    "    print(f\"Action taken: {actions[action]}\")\n",
    "    print(f\"Next State: {next_state}\")\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}\")\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87e3e263-712e-4c4b-b2ee-eb8f521b0421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(4)\n",
      "Observation Space: Discrete(48)\n",
      "Initial State: 36\n",
      "Action 0: Up\n",
      "Action 1: Right\n",
      "Action 2: Down\n",
      "Action 3: Left\n",
      "\n",
      "Simulating a few steps:\n",
      "\n",
      "Step 1:\n",
      "Action taken: Left\n",
      "Next State: 36\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "Step 2:\n",
      "Action taken: Left\n",
      "Next State: 36\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "Step 3:\n",
      "Action taken: Up\n",
      "Next State: 24\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "Step 4:\n",
      "Action taken: Up\n",
      "Next State: 12\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "Step 5:\n",
      "Action taken: Left\n",
      "Next State: 12\n",
      "Reward: -1\n",
      "Done: False\n"
     ]
    }
   ],
   "source": [
    "# CliffWalking-v1\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CliffWalking-v1')\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "print(f\"Action Space: {env.action_space}\")\n",
    "print(f\"Observation Space: {env.observation_space}\")\n",
    "\n",
    "print(f\"Initial State: {state}\")\n",
    "\n",
    "actions = {0: \"Up\", 1: \"Right\", 2: \"Down\", 3: \"Left\"}\n",
    "for action in actions:\n",
    "    print(f\"Action {action}: {actions[action]}\")\n",
    "\n",
    "num_steps = 5\n",
    "print(\"\\nSimulating a few steps:\")\n",
    "for step in range(num_steps):\n",
    "    action = env.action_space.sample() \n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    print(f\"\\nStep {step + 1}:\")\n",
    "    print(f\"Action taken: {actions[action]}\")\n",
    "    print(f\"Next State: {next_state}\")\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}\")\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
